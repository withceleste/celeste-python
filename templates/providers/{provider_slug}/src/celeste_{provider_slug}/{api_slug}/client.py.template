"""{Provider} {Api} API client mixin."""

from collections.abc import AsyncIterator
from typing import Any

import httpx

from celeste.client import APIMixin
from celeste.core import UsageField
from celeste.exceptions import StreamingNotSupportedError
from celeste.io import FinishReason
from celeste.mime_types import ApplicationMimeType

from . import config

# Optional: Import for Vertex AI support (when using GoogleADC auth).
# from ..auth import GoogleADC


class {Provider}{Api}Client(APIMixin):
    """Mixin for {Provider} {Api} API.

    Provides shared HTTP implementation:
    - _make_request(endpoint=...) - HTTP POST to specified endpoint
    - _make_stream_request() - HTTP streaming (if supported, otherwise raises StreamingNotSupportedError)
    - _make_poll_request() - Poll long-running operations (if supported, otherwise remove)
    - _parse_usage() - Extract usage dict from response
    - _parse_content() - Extract content from response
    - _parse_finish_reason() - Extract finish reason (if provided)
    - _build_metadata() - Filter content fields

    Auth-based endpoint selection (optional, for Google providers):
    - GoogleADC auth -> Vertex AI endpoints (via _build_url + _get_vertex_endpoint)
    - API key auth -> native API endpoints

    Modality clients pass endpoint parameter to route operations:
        await self._predict(inputs, endpoint=config.{Provider}{Api}Endpoint.CREATE_..., **parameters)
    """

    # Optional: Vertex AI endpoint routing. Add these two methods when the provider
    # supports Vertex AI. They replace the inline f"{config.BASE_URL}{endpoint}" URL
    # construction in _make_request() / _make_stream_request() with self._build_url(endpoint).
    #
    # def _get_vertex_endpoint(self, native_endpoint: str) -> str:
    #     """Map native endpoint to Vertex AI endpoint."""
    #     mapping: dict[str, str] = {
    #         config.{Provider}{Api}Endpoint.CREATE_...: config.Vertex{Api}Endpoint.CREATE_...,
    #     }
    #     vertex_endpoint = mapping.get(native_endpoint)
    #     if vertex_endpoint is None:
    #         raise ValueError(f"No Vertex AI endpoint mapping for: {native_endpoint}")
    #     return vertex_endpoint
    #
    # def _build_url(self, endpoint: str) -> str:
    #     """Build full URL based on auth type."""
    #     if isinstance(self.auth, GoogleADC):
    #         project_id = self.auth.resolved_project_id
    #         if project_id is None:
    #             raise ValueError(
    #                 "Vertex AI requires a project_id. "
    #                 "Pass project_id to GoogleADC() or ensure credentials have a project."
    #             )
    #         vertex_endpoint = self._get_vertex_endpoint(endpoint)
    #         base_url = self.auth.get_vertex_base_url()
    #         return f"{base_url}{vertex_endpoint.format(project_id=project_id, location=self.auth.location, model_id=self.model.id)}"
    #     return f"{config.BASE_URL}{endpoint.format(model_id=self.model.id)}"

    def _build_request(
        self,
        inputs: Any,
        extra_body: dict[str, Any] | None = None,
        streaming: bool = False,
        **parameters: Any,
    ) -> dict[str, Any]:
        """Build request with model ID and streaming flag."""
        request_body = super()._build_request(inputs, extra_body=extra_body, streaming=streaming, **parameters)
        request_body["model"] = self.model.id
        if streaming: request_body["stream"] = True
        return request_body

    async def _make_request(
        self,
        request_body: dict[str, Any],
        *,
        endpoint: str | None = None,
        **parameters: Any,
    ) -> dict[str, Any]:
        """Make HTTP request to {Provider} {Api} API."""
        if endpoint is None:
            endpoint = config.{Provider}{Api}Endpoint.CREATE_...

        headers = {
            **self.auth.get_headers(),
            "Content-Type": ApplicationMimeType.JSON,
        }

        response = await self.http_client.post(
            f"{config.BASE_URL}{endpoint}",
            headers=headers,
            json_body=request_body,
        )
        self._handle_error_response(response)
        data: dict[str, Any] = response.json()
        return data

    def _make_stream_request(
        self,
        request_body: dict[str, Any],
        *,
        endpoint: str | None = None,
        **parameters: Any,
    ) -> AsyncIterator[dict[str, Any]]:
        """Make streaming request to {Provider} {Api} API.

        If this API does not support streaming, replace this implementation with:
            def _make_stream_request(
                self,
                request_body: dict[str, Any],
                *,
                endpoint: str | None = None,
                **parameters: Any,
            ) -> AsyncIterator[dict[str, Any]]:
                \"\"\"{Provider} {Api} does not support SSE streaming in this client.\"\"\"
                raise StreamingNotSupportedError(model_id=self.model.id)
        """
        if endpoint is None:
            endpoint = config.{Provider}{Api}Endpoint.CREATE_...

        headers = {
            **self.auth.get_headers(),
            "Content-Type": ApplicationMimeType.JSON,
        }

        return self.http_client.stream_post(
            f"{config.BASE_URL}{endpoint}",
            headers=headers,
            json_body=request_body,
        )

    async def _make_poll_request(
        self,
        operation_name: str,
    ) -> dict[str, Any]:
        """Poll a long-running operation.

        If this API does not use long-running operations, remove this method.
        Override for Vertex AI support (POST to fetchPredictOperation).
        """
        headers = self.auth.get_headers()
        poll_url = f"{config.BASE_URL}{config.{Provider}{Api}Endpoint.GET_OPERATION.format(operation_name=operation_name)}"

        response = await self.http_client.get(
            poll_url,
            headers=headers,
        )
        self._handle_error_response(response)
        data: dict[str, Any] = response.json()
        return data

    @staticmethod
    def map_usage_fields(usage_data: dict[str, Any]) -> dict[str, int | float | None]:
        """Map {Provider} {Api} usage fields to unified names."""
        return {
            UsageField.INPUT_TOKENS: usage_data.get("..."),
            UsageField.OUTPUT_TOKENS: usage_data.get("..."),
            UsageField.TOTAL_TOKENS: usage_data.get("..."),
        }

    def _parse_usage(self, response_data: dict[str, Any]) -> dict[str, int | float | None]:
        """Extract usage data from {Provider} {Api} API response."""
        usage_data = response_data.get("...", {})
        return {Provider}{Api}Client.map_usage_fields(usage_data)

    def _parse_content(self, response_data: dict[str, Any]) -> Any:
        """Parse content from {Provider} {Api} API response."""
        content = response_data.get("...", [])
        if not content:
            msg = "No content in response"
            raise ValueError(msg)
        return content

    def _parse_finish_reason(self, response_data: dict[str, Any]) -> FinishReason:
        """Extract finish reason from {Provider} {Api} API response."""
        return FinishReason(reason=None)

    def _build_metadata(self, response_data: dict[str, Any]) -> dict[str, Any]:
        """Build metadata dictionary, filtering out content fields."""
        content_fields = {"..."}
        filtered_data = {
            k: v for k, v in response_data.items() if k not in content_fields
        }
        return super()._build_metadata(filtered_data)


__all__ = ["{Provider}{Api}Client"]
